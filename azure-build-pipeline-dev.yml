# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

trigger:
- master

pool:
  vmImage: 'ubuntu-latest'

container: 
  image: python:3.7
  options: -u root

steps:

- task: DownloadSecureFile@1
  name: SettingProfile
  displayName: 'Downloading Profile for Databricks'
  inputs:
    secureFile: 'profiles.yml'

- script: |
    echo Installing $(SettingProfile.secureFilePath) to the ~/.dbt...
    mkdir ~/.dbt
    cp $(SettingProfile.secureFilePath) ~/.dbt/profiles.yml
  displayName: Installing Profile for Databricks

- script: |
    sudo apt-get install git libpq-dev python-dev python3-pip libsasl2-dev
    sudo apt-get remove python-cffi
    sudo pip install --upgrade cffi
    pip install cryptography

- script: |
    pip install dbt 
    pip install "dbt-spark[PyHive]" 
    export PATH=$PATH:/home/vsts_azpcontainer/.local/bin
    pip dbt compile
    pip dbt test
    pip dbt run
  displayName: 'Compile, Test, and Run'